{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations_with_replacement\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from random import seed\n",
    "from random import random\n",
    "from math import exp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# normalize the dataset with minimal and max of each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    stats = [[min(column), max(column)] for column in zip(*dataset)]\n",
    "    return stats\n",
    "\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)-1):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrange the algorithms\n",
    "# 1. Initialize Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)]\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    network.append(output_layer)\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Forward Propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i]\n",
    "    return activation\n",
    "\n",
    "def transfer(activation):\n",
    "    return 1.0 / (1.0 + exp(-activation))\n",
    "\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)\n",
    "            neuron['output'] = transfer(activation)\n",
    "            new_inputs.append(neuron['output'])\n",
    "        inputs = new_inputs\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Back Propagate Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the derivative of an neuron output\n",
    "def transfer_derivative(output):\n",
    "    return output * (1.0 - output)\n",
    "\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]:\n",
    "                    error += (neuron['weights'][j] * neuron['delta'])\n",
    "                errors.append(error)\n",
    "        else:\n",
    "            for j in range(len(layer)):\n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output'])\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j]\n",
    "            neuron['delta'] = errors[j] * transfer_derivative(neuron['output'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(network, row, l_rate):\n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]]\n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j]\n",
    "            neuron['weights'][-1] += l_rate * neuron['delta']\n",
    "\n",
    "# Train a network for a fixed number of epochs\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network, row)\n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            backward_propagate_error(network, expected)\n",
    "            update_weights(network, row, l_rate)\n",
    "# Backpropagation Algorithm With Stochastic Gradient Descent\n",
    "def back_propagation(train, test, l_rate, n_epoch, n_hidden):\n",
    "    n_inputs = len(train[0]) - 1\n",
    "    n_outputs = len(set([row[-1] for row in train]))\n",
    "    network = initialize_network(n_inputs, n_hidden, n_outputs)\n",
    "    train_network(network, train, l_rate, n_epoch, n_outputs)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = predict(network, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "# Make a prediction with a network\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Project+4.pdf', 'spambase.data', 'spambase.names', 'Project4.ipynb', '.ipynb_checkpoints', 'df_score_raw.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for l_rate = 0.100000, n_epoch=5 is: 84.375%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=10 is: 89.565%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=15 is: 90.299%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=20 is: 91.576%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=5 is: 87.935%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=10 is: 91.549%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=15 is: 91.141%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=20 is: 92.554%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=5 is: 89.538%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=10 is: 91.658%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=15 is: 91.413%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=20 is: 91.359%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=5 is: 90.652%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=10 is: 90.190%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=15 is: 91.902%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=20 is: 92.174%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=5 is: 91.332%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=10 is: 91.250%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=15 is: 82.038%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=20 is: 92.391%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=5 is: 90.353%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=10 is: 92.147%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=15 is: 92.310%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=20 is: 91.603%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=5 is: 90.842%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=10 is: 88.560%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=15 is: 88.505%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=20 is: 92.065%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=5 is: 86.766%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=10 is: 92.092%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=15 is: 91.005%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=20 is: 90.815%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=5 is: 91.875%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=10 is: 91.766%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=15 is: 91.957%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=20 is: 89.891%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=5 is: 91.359%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=10 is: 91.929%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=15 is: 92.391%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=20 is: 92.310%\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "data = []\n",
    "with open('spambase.data', 'r') as file:\n",
    "    csv = reader(file)\n",
    "    for row in csv:\n",
    "        if not row:\n",
    "            continue\n",
    "        data.append(row)\n",
    "        \n",
    "shuffle(data)\n",
    "#indices = np.random.permutation(len(data))\n",
    "n_training_samples = 3680\n",
    "# split into train and test datasets \n",
    "learnset_data = data[:n_training_samples]\n",
    "testset_data = data[n_training_samples:]\n",
    "\n",
    "for i in range(len(learnset_data[0])-1):\n",
    "    str_column_to_float(learnset_data, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(learnset_data, len(learnset_data[0])-1)\n",
    "# normalize input variables\n",
    "minmax = dataset_minmax(learnset_data)\n",
    "normalize_dataset(learnset_data, minmax)\n",
    "\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = [x/10 for x in range(1,11,1)]\n",
    "n_epoch = [5,10,15,20]\n",
    "n_hidden = 5\n",
    "score_raw = []\n",
    "for i in l_rate:\n",
    "    for j in n_epoch:\n",
    "        scores = evaluate_algorithm(learnset_data, back_propagation, n_folds, i, j, n_hidden)\n",
    "        ave_score = sum(scores) / len(scores)\n",
    "        score_raw.append(ave_score)\n",
    "\n",
    "        #print('Scores: %s' % scores)\n",
    "        print('Mean Accuracy for l_rate = %f, n_epoch=%d is: %.3f%%' % (i, j, ave_score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score_raw</th>\n",
       "      <th>epoch</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.375000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89.565217</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.298913</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91.576087</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.934783</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>91.548913</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>91.141304</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>92.554348</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>89.538043</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>91.657609</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91.413043</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>91.358696</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.652174</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90.190217</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91.902174</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>92.173913</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>91.331522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>91.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>82.038043</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>92.391304</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.353261</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>92.146739</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>92.309783</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>91.603261</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90.842391</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>88.559783</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>88.505435</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>92.065217</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>86.766304</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>92.092391</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>91.005435</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>90.815217</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>91.875000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>91.766304</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>91.956522</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>89.891304</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>91.358696</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>91.929348</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>92.391304</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>92.309783</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    score_raw  epoch  rate\n",
       "0   84.375000      5   0.1\n",
       "1   89.565217     10   0.1\n",
       "2   90.298913     15   0.1\n",
       "3   91.576087     20   0.1\n",
       "4   87.934783      5   0.2\n",
       "5   91.548913     10   0.2\n",
       "6   91.141304     15   0.2\n",
       "7   92.554348     20   0.2\n",
       "8   89.538043      5   0.3\n",
       "9   91.657609     10   0.3\n",
       "10  91.413043     15   0.3\n",
       "11  91.358696     20   0.3\n",
       "12  90.652174      5   0.4\n",
       "13  90.190217     10   0.4\n",
       "14  91.902174     15   0.4\n",
       "15  92.173913     20   0.4\n",
       "16  91.331522      5   0.5\n",
       "17  91.250000     10   0.5\n",
       "18  82.038043     15   0.5\n",
       "19  92.391304     20   0.5\n",
       "20  90.353261      5   0.6\n",
       "21  92.146739     10   0.6\n",
       "22  92.309783     15   0.6\n",
       "23  91.603261     20   0.6\n",
       "24  90.842391      5   0.7\n",
       "25  88.559783     10   0.7\n",
       "26  88.505435     15   0.7\n",
       "27  92.065217     20   0.7\n",
       "28  86.766304      5   0.8\n",
       "29  92.092391     10   0.8\n",
       "30  91.005435     15   0.8\n",
       "31  90.815217     20   0.8\n",
       "32  91.875000      5   0.9\n",
       "33  91.766304     10   0.9\n",
       "34  91.956522     15   0.9\n",
       "35  89.891304     20   0.9\n",
       "36  91.358696      5   1.0\n",
       "37  91.929348     10   1.0\n",
       "38  92.391304     15   1.0\n",
       "39  92.309783     20   1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score_raw = pd.DataFrame({'score_raw': score_raw})\n",
    "epoch = np.array([x for x in range(5,25,5)]*10)\n",
    "x = np.array([x/10 for x in range(1,11,1)])\n",
    "rate = np.repeat(x, [4], axis=0)\n",
    "df_score_raw['epoch'] = pd.DataFrame({'epoch': epoch})\n",
    "df_score_raw['rate'] = pd.DataFrame({'rate': rate})\n",
    "#df_score_raw.to_csv('df_score_raw.csv')\n",
    "piv = pd.pivot_table(df_score_raw, values=\"score_raw\",index=[\"rate\"], columns=[\"epoch\"], fill_value=0)\n",
    "ax = sns.heatmap(piv, square=True)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90 )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df_score_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the testdata with the best training paramters, epoch=20, learning rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testset_data[0])-1):\n",
    "    str_column_to_float(testset_data, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(testset_data, len(learnset_data[0])-1)\n",
    "# normalize input variables\n",
    "minmax = dataset_minmax(testset_data)\n",
    "normalize_dataset(testset_data, minmax)\n",
    "\n",
    "predicted_test = back_propagation(learnset_data, testset_data, 0.2, 20, n_hidden)\n",
    "actual = [row[-1] for row in testset_data]\n",
    "accuracy = accuracy_metric(actual, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0         1          1\n",
       "1         1          1\n",
       "2         0          0\n",
       "3         0          0\n",
       "4         0          0\n",
       "5         1          1\n",
       "6         1          1\n",
       "7         1          1\n",
       "8         0          0\n",
       "9         0          1\n",
       "10        1          1\n",
       "11        1          1\n",
       "12        0          0\n",
       "13        0          0\n",
       "14        1          1\n",
       "15        0          0\n",
       "16        0          0\n",
       "17        1          1\n",
       "18        0          0\n",
       "19        0          0\n",
       "20        0          0\n",
       "21        1          1\n",
       "22        0          0\n",
       "23        1          1\n",
       "24        0          0\n",
       "25        0          0\n",
       "26        1          1\n",
       "27        1          1\n",
       "28        1          1\n",
       "29        1          1\n",
       "..      ...        ...\n",
       "891       0          0\n",
       "892       1          1\n",
       "893       0          1\n",
       "894       1          1\n",
       "895       0          0\n",
       "896       1          1\n",
       "897       0          1\n",
       "898       1          1\n",
       "899       1          1\n",
       "900       1          0\n",
       "901       0          0\n",
       "902       1          1\n",
       "903       0          0\n",
       "904       0          1\n",
       "905       0          0\n",
       "906       1          1\n",
       "907       0          0\n",
       "908       0          1\n",
       "909       1          1\n",
       "910       0          0\n",
       "911       1          1\n",
       "912       1          1\n",
       "913       0          0\n",
       "914       0          0\n",
       "915       0          0\n",
       "916       0          0\n",
       "917       1          1\n",
       "918       0          1\n",
       "919       1          1\n",
       "920       1          1\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predict = pd.DataFrame({'actual': actual})\n",
    "df_predict['predicted'] = pd.DataFrame({'predicted_test': predicted_test})\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8534 427 359 121 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_no</th>\n",
       "      <th>predicted_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no</th>\n",
       "      <td>427</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_yes</th>\n",
       "      <td>14</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_no  predicted_yes\n",
       "actual_no            427            121\n",
       "actual_yes            14            359"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = sum((df_predict['actual']==1) & (df_predict['predicted']==1)) \n",
    "TN = sum((df_predict['actual']==0) & (df_predict['predicted']==0)) \n",
    "FP = sum((df_predict['actual']==0) & (df_predict['predicted']==1)) \n",
    "FN = sum((df_predict['actual']==1) & (df_predict['predicted']==0)) \n",
    "# confusion matrix\n",
    "# Accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "Acuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(round(Acuracy,4), TN, TP, FP, FN) \n",
    "score_matrix = pd.DataFrame([[TN, FP], [FN, TP]])\n",
    "score_matrix \n",
    "score_matrix.rename(columns={0:'predicted_no',1:'predicted_yes'}, index={0:'actual_no',1:'actual_yes'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension reduction with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('spambase.data', 'r') as file:\n",
    "    csv = reader(file)\n",
    "    for row in csv:\n",
    "        if not row:\n",
    "            continue\n",
    "        data.append(row)\n",
    "shuffle(data)    \n",
    "X = [row[:-1] for row in data]\n",
    "Y = [row[-1] for row in data]\n",
    "X = np.array(X).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize input variables\n",
    "X_stand = (X - X.min(axis=0))/(X.max(axis=0)-X.min(axis=0))\n",
    "u, s, vh = np.linalg.svd(X_stand)\n",
    "np.cumsum(s**2) / sum(s**2)  \n",
    "## 32 pcs\n",
    "X_pca = X_stand @ vh.T[:,:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = [list(row) for row in X_pca]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = [x + [int(y)] for x, y in zip(X_pca, Y)]\n",
    "n_training_samples = 3680\n",
    "# split into train and test datasets \n",
    "learnset_pca_data = pca_data[:n_training_samples]\n",
    "testset_pca_data = pca_data[n_training_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy for l_rate = 0.100000, n_epoch=5 is: 85.598%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=10 is: 88.886%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=15 is: 89.103%\n",
      "Mean Accuracy for l_rate = 0.100000, n_epoch=20 is: 90.924%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=5 is: 89.457%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=10 is: 90.462%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=15 is: 90.217%\n",
      "Mean Accuracy for l_rate = 0.200000, n_epoch=20 is: 91.304%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=5 is: 86.712%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=10 is: 90.652%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=15 is: 89.701%\n",
      "Mean Accuracy for l_rate = 0.300000, n_epoch=20 is: 90.625%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=5 is: 88.777%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=10 is: 90.054%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=15 is: 91.141%\n",
      "Mean Accuracy for l_rate = 0.400000, n_epoch=20 is: 90.761%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=5 is: 90.136%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=10 is: 90.353%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=15 is: 90.788%\n",
      "Mean Accuracy for l_rate = 0.500000, n_epoch=20 is: 90.163%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=5 is: 90.054%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=10 is: 89.783%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=15 is: 90.217%\n",
      "Mean Accuracy for l_rate = 0.600000, n_epoch=20 is: 90.870%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=5 is: 90.299%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=10 is: 91.250%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=15 is: 91.168%\n",
      "Mean Accuracy for l_rate = 0.700000, n_epoch=20 is: 90.897%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=5 is: 90.598%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=10 is: 90.245%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=15 is: 91.060%\n",
      "Mean Accuracy for l_rate = 0.800000, n_epoch=20 is: 91.522%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=5 is: 88.940%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=10 is: 90.353%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=15 is: 85.435%\n",
      "Mean Accuracy for l_rate = 0.900000, n_epoch=20 is: 81.957%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=5 is: 90.272%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=10 is: 87.011%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=15 is: 91.033%\n",
      "Mean Accuracy for l_rate = 1.000000, n_epoch=20 is: 90.462%\n"
     ]
    }
   ],
   "source": [
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "l_rate = [x/10 for x in range(1,11,1)]\n",
    "n_epoch = [5,10,15,20]\n",
    "n_hidden = 5\n",
    "score = []\n",
    "for i in l_rate:\n",
    "    for j in n_epoch:\n",
    "        scores = evaluate_algorithm(learnset_pca_data, back_propagation, n_folds, i, j, n_hidden)\n",
    "        ave_score = sum(scores) / len(scores)\n",
    "        score.append(ave_score)\n",
    "\n",
    "        #print('Scores: %s' % scores)\n",
    "        print('Mean Accuracy for l_rate = %f, n_epoch=%d is: %.3f%%' % (i, j, ave_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>epoch</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.597826</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88.885870</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89.103261</td>\n",
       "      <td>15</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.923913</td>\n",
       "      <td>20</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89.456522</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>90.461957</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>90.217391</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>91.304348</td>\n",
       "      <td>20</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>86.711957</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>90.652174</td>\n",
       "      <td>10</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>89.701087</td>\n",
       "      <td>15</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>90.625000</td>\n",
       "      <td>20</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>88.777174</td>\n",
       "      <td>5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>90.054348</td>\n",
       "      <td>10</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>91.141304</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>90.760870</td>\n",
       "      <td>20</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90.135870</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90.353261</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>90.788043</td>\n",
       "      <td>15</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>90.163043</td>\n",
       "      <td>20</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.054348</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>89.782609</td>\n",
       "      <td>10</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>90.217391</td>\n",
       "      <td>15</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>90.869565</td>\n",
       "      <td>20</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>90.298913</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>91.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>91.168478</td>\n",
       "      <td>15</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>90.896739</td>\n",
       "      <td>20</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>90.597826</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>90.244565</td>\n",
       "      <td>10</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>91.059783</td>\n",
       "      <td>15</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>91.521739</td>\n",
       "      <td>20</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>88.940217</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>90.353261</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>85.434783</td>\n",
       "      <td>15</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>81.956522</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>90.271739</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>87.010870</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>91.032609</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>90.461957</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score  epoch  rate\n",
       "0   85.597826      5   0.1\n",
       "1   88.885870     10   0.1\n",
       "2   89.103261     15   0.1\n",
       "3   90.923913     20   0.1\n",
       "4   89.456522      5   0.2\n",
       "5   90.461957     10   0.2\n",
       "6   90.217391     15   0.2\n",
       "7   91.304348     20   0.2\n",
       "8   86.711957      5   0.3\n",
       "9   90.652174     10   0.3\n",
       "10  89.701087     15   0.3\n",
       "11  90.625000     20   0.3\n",
       "12  88.777174      5   0.4\n",
       "13  90.054348     10   0.4\n",
       "14  91.141304     15   0.4\n",
       "15  90.760870     20   0.4\n",
       "16  90.135870      5   0.5\n",
       "17  90.353261     10   0.5\n",
       "18  90.788043     15   0.5\n",
       "19  90.163043     20   0.5\n",
       "20  90.054348      5   0.6\n",
       "21  89.782609     10   0.6\n",
       "22  90.217391     15   0.6\n",
       "23  90.869565     20   0.6\n",
       "24  90.298913      5   0.7\n",
       "25  91.250000     10   0.7\n",
       "26  91.168478     15   0.7\n",
       "27  90.896739     20   0.7\n",
       "28  90.597826      5   0.8\n",
       "29  90.244565     10   0.8\n",
       "30  91.059783     15   0.8\n",
       "31  91.521739     20   0.8\n",
       "32  88.940217      5   0.9\n",
       "33  90.353261     10   0.9\n",
       "34  85.434783     15   0.9\n",
       "35  81.956522     20   0.9\n",
       "36  90.271739      5   1.0\n",
       "37  87.010870     10   1.0\n",
       "38  91.032609     15   1.0\n",
       "39  90.461957     20   1.0"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score = pd.DataFrame({'score': score})\n",
    "epoch = np.array([x for x in range(5,25,5)]*10)\n",
    "x = np.array([x/10 for x in range(1,11,1)])\n",
    "rate = np.repeat(x, [4], axis=0)\n",
    "df_score['epoch'] = pd.DataFrame({'epoch': epoch})\n",
    "df_score['rate'] = pd.DataFrame({'rate': rate})\n",
    "#df_score_raw.to_csv('df_score_raw.csv')\n",
    "piv = pd.pivot_table(df_score, values=\"score\",index=[\"rate\"], columns=[\"epoch\"], fill_value=0)\n",
    "ax = sns.heatmap(piv, square=True)\n",
    "plt.setp(ax.xaxis.get_majorticklabels(), rotation=90 )\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the testdata with the best training paramters, epoch=20, learning rate=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0         0          0\n",
       "1         0          0\n",
       "2         0          0\n",
       "3         1          1\n",
       "4         1          1\n",
       "5         0          0\n",
       "6         0          0\n",
       "7         0          0\n",
       "8         0          0\n",
       "9         0          0\n",
       "10        0          0\n",
       "11        0          0\n",
       "12        0          0\n",
       "13        0          0\n",
       "14        0          0\n",
       "15        0          0\n",
       "16        1          1\n",
       "17        1          1\n",
       "18        1          1\n",
       "19        1          1\n",
       "20        0          0\n",
       "21        0          0\n",
       "22        1          0\n",
       "23        1          0\n",
       "24        0          1\n",
       "25        0          0\n",
       "26        0          0\n",
       "27        1          1\n",
       "28        1          1\n",
       "29        0          0\n",
       "..      ...        ...\n",
       "891       0          0\n",
       "892       1          1\n",
       "893       0          0\n",
       "894       0          0\n",
       "895       0          0\n",
       "896       1          1\n",
       "897       1          1\n",
       "898       1          1\n",
       "899       0          0\n",
       "900       1          1\n",
       "901       1          1\n",
       "902       0          0\n",
       "903       0          0\n",
       "904       0          0\n",
       "905       0          0\n",
       "906       1          1\n",
       "907       1          1\n",
       "908       0          1\n",
       "909       1          1\n",
       "910       1          1\n",
       "911       0          0\n",
       "912       0          0\n",
       "913       1          0\n",
       "914       0          0\n",
       "915       0          0\n",
       "916       0          0\n",
       "917       1          1\n",
       "918       0          0\n",
       "919       0          1\n",
       "920       1          1\n",
       "\n",
       "[921 rows x 2 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_pca_test = back_propagation(learnset_pca_data, testset_pca_data, 0.8, 20, n_hidden)\n",
    "actual = [row[-1] for row in testset_pca_data]\n",
    "accuracy = accuracy_metric(actual, predicted_pca_test)\n",
    "\n",
    "df_predict = pd.DataFrame({'actual': actual})\n",
    "df_predict['predicted'] = pd.DataFrame({'predicted_test': predicted_pca_test})\n",
    "df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9327 549 310 26 36\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_no</th>\n",
       "      <th>predicted_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_no</th>\n",
       "      <td>549</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_yes</th>\n",
       "      <td>36</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            predicted_no  predicted_yes\n",
       "actual_no            549             26\n",
       "actual_yes            36            310"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP = sum((df_predict['actual']==1) & (df_predict['predicted']==1)) \n",
    "TN = sum((df_predict['actual']==0) & (df_predict['predicted']==0)) \n",
    "FP = sum((df_predict['actual']==0) & (df_predict['predicted']==1)) \n",
    "FN = sum((df_predict['actual']==1) & (df_predict['predicted']==0)) \n",
    "# confusion matrix\n",
    "# Accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "Acuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(round(Acuracy,4), TN, TP, FP, FN) \n",
    "score_matrix = pd.DataFrame([[TN, FP], [FN, TP]])\n",
    "score_matrix \n",
    "score_matrix.rename(columns={0:'predicted_no',1:'predicted_yes'}, index={0:'actual_no',1:'actual_yes'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
